{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task1_0619. 다음 사항을 수행하세요.\n",
    "- 첫 번째로 매칭되는 'p' 태그 찾기\n",
    "- 모든 'p' 태그 찾기\n",
    "- 클래스가 'content'인 첫 번째 'p' 태그 찾기\n",
    "- 클래스가 'content'인 모든 'p' 태그 찾기\n",
    "- 특정 'p' 태그의 모든 부모 태그 찾기\n",
    "- 특정 'p' 태그의 첫 번째 부모 태그 찾기\n",
    "- 특정 'p' 태그의 다음 형제 태그 찾기\n",
    "- 특정 'p' 태그의 이전 형제 태그 찾기\n",
    "- 특정 'p' 태그 다음에 위치한 모든 태그나 문자열 찾기\n",
    "- 특정 'p' 태그 이전에 위치한 모든 태그나 문자열 찾기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<html>\n",
      " <body>\n",
      "  <h1>\n",
      "   Title\n",
      "  </h1>\n",
      "  <p class=\"content\">\n",
      "   First paragraph.\n",
      "  </p>\n",
      "  <p class=\"content\">\n",
      "   Second paragraph.\n",
      "  </p>\n",
      " </body>\n",
      "</html>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup \n",
    "\n",
    "html_contents='<html><body><h1>Title</h1><p class=\"content\">First paragraph.</p><p class=\"content\">Second paragraph.</p></body></html>'\n",
    "soup=BeautifulSoup(html_contents,'html.parser')\n",
    "print(soup.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "#1 첫 번째 'p' 태그\n",
      "<p class=\"content\">First paragraph.</p>\n",
      "First paragraph.\n",
      "\n",
      "#2 모든 'p' 태그\n",
      "<p class=\"content\">First paragraph.</p>\n",
      "<p class=\"content\">Second paragraph.</p>\n",
      "\n",
      "#3 클래스가 'content'인 첫 번째 'p' 태그\n",
      "<p class=\"content\">First paragraph.</p>\n",
      "\n",
      "#4 클래스가 'content'인 모든 'p' 태그\n",
      "<p class=\"content\">First paragraph.</p>\n",
      "<p class=\"content\">Second paragraph.</p>\n",
      "\n",
      "#5 'p' 태그의 모든 부모 태그\n",
      "<p class=\"content\">First paragraph.</p>의 부모 태그: [<body><h1>Title</h1><p class=\"content\">First paragraph.</p><p class=\"content\">Second paragraph.</p></body>, <html><body><h1>Title</h1><p class=\"content\">First paragraph.</p><p class=\"content\">Second paragraph.</p></body></html>, <html><body><h1>Title</h1><p class=\"content\">First paragraph.</p><p class=\"content\">Second paragraph.</p></body></html>]\n",
      "<p class=\"content\">Second paragraph.</p>의 부모 태그: [<body><h1>Title</h1><p class=\"content\">First paragraph.</p><p class=\"content\">Second paragraph.</p></body>, <html><body><h1>Title</h1><p class=\"content\">First paragraph.</p><p class=\"content\">Second paragraph.</p></body></html>, <html><body><h1>Title</h1><p class=\"content\">First paragraph.</p><p class=\"content\">Second paragraph.</p></body></html>]\n",
      "\n",
      "#6 'p' 태그의 첫번째 부모 태그\n",
      "<p class=\"content\">First paragraph.</p>의 부모 태그: <body><h1>Title</h1><p class=\"content\">First paragraph.</p><p class=\"content\">Second paragraph.</p></body>\n",
      "<p class=\"content\">Second paragraph.</p>의 부모 태그: <body><h1>Title</h1><p class=\"content\">First paragraph.</p><p class=\"content\">Second paragraph.</p></body>\n",
      "\n",
      "#7 'p' 태그의 다음 형제 태그\n",
      "<p class=\"content\">First paragraph.</p>의 다음 형제 태그: <p class=\"content\">Second paragraph.</p>\n",
      "<p class=\"content\">Second paragraph.</p>의 다음 형제 태그: None\n",
      "\n",
      "#8 'p' 태그의 이전 형제 태그\n",
      "<p class=\"content\">First paragraph.</p>의 이전 형제 태그: <h1>Title</h1>\n",
      "<p class=\"content\">Second paragraph.</p>의 이전 형제 태그: <p class=\"content\">First paragraph.</p>\n",
      "\n",
      "#9 'p' 태그의 다음에 위치한 모든 태그나 문자열 찾기\n",
      "<p class=\"content\">First paragraph.</p>의 다음 형제 태그: [<p class=\"content\">Second paragraph.</p>]\n",
      "<p class=\"content\">Second paragraph.</p>의 다음 형제 태그: []\n",
      "\n",
      "#10 'p' 태그의 이전에 위치한 모든 태그나 문자열 찾기\n",
      "<p class=\"content\">First paragraph.</p>의 이전 형제 태그: [<h1>Title</h1>]\n",
      "<p class=\"content\">Second paragraph.</p>의 이전 형제 태그: [<p class=\"content\">First paragraph.</p>, <h1>Title</h1>]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup \n",
    "\n",
    "html_contents='<html><body><h1>Title</h1><p class=\"content\">First paragraph.</p><p class=\"content\">Second paragraph.</p></body></html>'\n",
    "soup=BeautifulSoup(html_contents,'html.parser')\n",
    "#print(soup.prettify())\n",
    "\n",
    "## 1\n",
    "print(\"\\n#1 첫 번째 'p' 태그\")\n",
    "tag=soup.find('p')\n",
    "print(tag)\n",
    "print(tag.get_text())\n",
    "\n",
    "## 2\n",
    "print(\"\\n#2 모든 'p' 태그\")\n",
    "tags=soup.find_all('p')\n",
    "for tag in tags:\n",
    "    print(tag)\n",
    "\n",
    "## 3\n",
    "print(\"\\n#3 클래스가 'content'인 첫 번째 'p' 태그\")\n",
    "content_p=soup.find('p', class_='content')      \n",
    "print(content_p)\n",
    "\n",
    "## 4\n",
    "print(\"\\n#4 클래스가 'content'인 모든 'p' 태그\")\n",
    "content_ps=soup.find_all('p', class_='content')      \n",
    "for content_p in content_ps:\n",
    "    print(content_p)\n",
    "\n",
    "## 5 [doc] ==> <html> ==> <body> ==> <p> : 최상위 요소에서 p태그까지 모든 부모 요소를 출력하게 됨\n",
    "print(\"\\n#5 'p' 태그의 모든 부모 태그\")\n",
    "content_ps=soup.find_all('p')      \n",
    "for content_p in content_ps:\n",
    "    parents=content_p.find_parents()\n",
    "    print(f\"{content_p}의 부모 태그: {parents}\")\n",
    "\n",
    "## 6\n",
    "print(\"\\n#6 'p' 태그의 첫번째 부모 태그\")\n",
    "content_ps=soup.find_all('p')      \n",
    "for content_p in content_ps:\n",
    "    parent=content_p.find_parent()\n",
    "    print(f\"{content_p}의 부모 태그: {parent}\")\n",
    "\n",
    "## 7\n",
    "print(\"\\n#7 'p' 태그의 다음 형제 태그\")\n",
    "content_ps=soup.find_all('p')      \n",
    "for content_p in content_ps:\n",
    "    next_sib=content_p.find_next_sibling()\n",
    "    print(f\"{content_p}의 다음 형제 태그: {next_sib}\")\n",
    "\n",
    "## 8\n",
    "print(\"\\n#8 'p' 태그의 이전 형제 태그\")\n",
    "content_ps=soup.find_all('p')      \n",
    "for content_p in content_ps:\n",
    "    prev_sib=content_p.find_previous_sibling()\n",
    "    print(f\"{content_p}의 이전 형제 태그: {prev_sib}\")\n",
    "\n",
    "## 9\n",
    "print(\"\\n#9 'p' 태그의 다음에 위치한 모든 태그나 문자열 찾기\")\n",
    "content_ps=soup.find_all('p')      \n",
    "for content_p in content_ps:\n",
    "    next_sibs=content_p.find_next_siblings()\n",
    "    print(f\"{content_p}의 다음 형제 태그: {next_sibs}\")\n",
    "\n",
    "## 10\n",
    "print(\"\\n#10 'p' 태그의 이전에 위치한 모든 태그나 문자열 찾기\")\n",
    "content_ps=soup.find_all('p')      \n",
    "for content_p in content_ps:\n",
    "    prev_sibs=content_p.find_previous_siblings()\n",
    "    print(f\"{content_p}의 이전 형제 태그: {prev_sibs}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First paragraph.\n",
      "First paragraph.\n",
      "Second paragraph.\n",
      "First paragraph.\n",
      "First paragraph.\n",
      "Second paragraph.\n",
      "<body><h1>Title</h1><p class=\"content\">First paragraph.</p><p class=\"content\">Second paragraph.</p></body>\n",
      "<html><body><h1>Title</h1><p class=\"content\">First paragraph.</p><p class=\"content\">Second paragraph.</p></body></html>\n",
      "<html><body><h1>Title</h1><p class=\"content\">First paragraph.</p><p class=\"content\">Second paragraph.</p></body></html>\n",
      "<html><body><h1>Title</h1><p class=\"content\">First paragraph.</p><p class=\"content\">Second paragraph.</p></body></html>\n",
      "\n",
      "#9 'p' 태그의 다음에 위치한 모든 태그나 문자열 찾기\n",
      "<p class=\"content\">First paragraph.</p>의 다음 모든 태그, 문자열: <p class=\"content\">Second paragraph.</p>\n",
      "\n",
      "#10 'p' 태그의 이전에 위치한 모든 태그나 문자열 찾기\n",
      "<p class=\"content\">First paragraph.</p>의 이전 모든 태그, 문자열: <h1>Title</h1>\n"
     ]
    }
   ],
   "source": [
    "### 강사님 답안\n",
    "#1 \n",
    "tag=soup.find('p')\n",
    "print(tag.get_text())\n",
    "#2 \n",
    "tags=soup.find_all('p')\n",
    "for tag in tags:\n",
    "    print(tag.get_text())\n",
    "#3\n",
    "first_content_p=soup.select_one('p.content')\n",
    "print(first_content_p.get_text())\n",
    "#4\n",
    "all_content_p=soup.select('p.content')\n",
    "for content_p in all_content_p:\n",
    "    print(content_p.get_text())\n",
    "#5\n",
    "specific_content_p=soup.select_one('p.content')\n",
    "paraents=specific_content_p.find_parents()\n",
    "for parent in parents:\n",
    "    print(parent)\n",
    "\n",
    "#6\n",
    "paraent=specific_content_p.find_parent()\n",
    "print(parent)\n",
    "\n",
    "\n",
    "## 9\n",
    "print(\"\\n#9 'p' 태그의 다음에 위치한 모든 태그나 문자열 찾기\")\n",
    "specific_p=soup.find('p', class_='content')      \n",
    "nexts=specific_p.find_next()\n",
    "print(f\"{specific_p}의 다음 모든 태그, 문자열: {nexts}\")\n",
    "\n",
    "## 10\n",
    "print(\"\\n#10 'p' 태그의 이전에 위치한 모든 태그나 문자열 찾기\")\n",
    "specific_p=soup.find('p', class_='content')      \n",
    "prev=specific_p.find_previous()\n",
    "print(f\"{specific_p}의 이전 모든 태그, 문자열: {prev}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task2_0619. ID를 이용해서 '네이버 뉴스' 추출하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<title id=\"browserTitleArea\">네이버 뉴스</title>\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup \n",
    "\n",
    "## 예시 네이버 뉴스 페이지 URL\n",
    "url='https://news.naver.com'\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3',\n",
    "    'Accept-Language': 'en-US,en;q=0.9',\n",
    "    'Referer': 'http://example.com'\n",
    "}\n",
    "response=requests.get(url, headers=headers)\n",
    "\n",
    "\n",
    "soup=BeautifulSoup(response.text,'html.parser')\n",
    "#NaverNews=soup.select_one('#browserTitleArea')\n",
    "## 강사님\n",
    "NaverNews=soup.find('title', id='browserTitleArea')\n",
    "NaverNews=soup.select_one('title#browserTitleArea')\n",
    "#print(NaverNews.get_text())\n",
    "print(NaverNews)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task3_0619. soup.find_all(class_='Nitem_link_menu') 대신에 select를 이용하여 동일한 결과를 출력하세요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: 언론사별\n",
      "2: 정치\n",
      "3: 경제\n",
      "4: 사회\n",
      "5: 생활/문화\n",
      "6: IT/과학\n",
      "7: 세계\n",
      "8: 랭킹\n",
      "9: 신문보기\n",
      "10: 오피니언\n",
      "11: TV\n",
      "12: 팩트체크\n",
      "13: 알고리즘 안내\n",
      "14: 정정보도 모음\n"
     ]
    }
   ],
   "source": [
    "### 네이버 뉴스에서 언론사별 ... 카테고리 출력\n",
    "cats=soup.select('.Nitem_link_menu')\n",
    "for idx,cat in enumerate(cats):\n",
    "    print(f\"{idx+1}: {cat.get_text().strip()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task4_0619. select_one을 이용해서 'https://news.naver.com'에서 \"뉴스\"를 출력하세요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "뉴스\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = 'https://news.naver.com'\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "#element = soup.select_one('a[href*=\"news.naver.com\"]')\n",
    "# 강사님\n",
    "element=soup.select_one('span.Nicon_service')              # span 태그에서 Nicon_service 클래스\n",
    "\n",
    "if element:\n",
    "    print(element.text.strip())\n",
    "else:\n",
    "    print(\"해당 요소를 찾을 수 없습니다.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task5_0619.'https://news.naver.com'에서 아래 예시와 같이 뉴스 기사 제목을 모두 출력하세요. \n",
    "\n",
    "예시: 1: [속보] '훈련병 사망' 얼차려 지시 중대장·부중대장 피의자 신분 첫 소환조사"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: \"자식 돈은 자식 돈, 어디 숟가락을 얹나\"…박세리 논란에 손웅정 발언 재조명\n",
      "2: 대통령실 '길목' 첫 조사…관심 모드는 김건희 여사 조사\n",
      "3: \"저출산 국가비상사태 선언\"…무더기 상한가 속출\n",
      "4: 오물 풍선 소동, 끝난 게 아니다\n",
      "5: [도초도 수국축제] 지금 만나러 갑니다 1004만 송이 수국\n",
      "6: 북러, 포괄적 동반자 협정 체결 \"침략 당하면 상호지원\"\n",
      "7: [인터뷰] “한국 넘버원 역직구 플랫폼 꿈꾸죠”…딜리버드코리아 직원들의 자신감\n",
      "8: \"몸이 갑자기 거인처럼 커진다\" 감각이 왜곡된다는 女, 무슨 증후군?\n",
      "9: [이사람] 영업이익 18조원 달성한 정의선 회장…국내 그룹 총수 중 '최고'\n",
      "10: 에코+페미, 우리 지금 만나\n",
      "11: 은행 슈퍼앱, 디지털 헬스케어 품는다\n",
      "12: 목동 아파트 화재 12시간 만에 진압…긴박했던 순간들\n",
      "13: 1주기 앞두고 오송참사 현장 찾은 유족들 '짙은 안타까움'...재개통 우려도\n",
      "14: “귀엽지만 음식에 털 날려서…” 반려동물 식당 출입에 곳곳 갈등\n",
      "15: 민주당내 '이재명 아버지' 발언에 진중권 \"연호도 붙여줘라\"\n",
      "16: 현빈이 입은 '이 옷' 해외서도 난리…주가 58% 뛰었는데 \"더 뛴다\"\n",
      "17: 김호중 음주운전 혐의 제외에…\"우리도 도망가자\" 공분\n",
      "18: \"옵션 추가하면 10억\"…전기차 첫 출시 앞둔 '이 브랜드' 판매 전략은\n",
      "19: ‘홍의 시대’ 열린다…막 오른 GS家 4세들의 승계 경쟁\n",
      "20: \"한쪽 침략당하면 상호지원\"…랍스터 먹고, 한밤 배웅까지\n",
      "21: 비대면 대출 해준다더니…돌아온 건 계좌 정지\n",
      "22: ‘형만 믿어’…한반도 유사시 러시아 개입 길 열렸다 [뉴스+]\n",
      "23: 백종원·곽튜브 제쳤다… 한국인이 좋아하는 유튜버 1위는?\n",
      "24: \"외로울 틈이 없어요\" 입주민들과 여행 가고 동아리 활동까지…'위스테이별내' 풍경[르포]\n",
      "25: 박세리 부친 입 열었다 \"아빠니까 나설 수 있다는 생각\"\n",
      "26: 권도형 구금 몬테네그로 총리, 알고 보니 ‘테라 초기 투자자’\n",
      "27: “자식 돈에 어디 숟가락”…박세리 논란에 소환된 손웅정\n",
      "28: ‘미투’ 서지현 검사 근황 보니…“정치권, ‘이대남’ 표 위해 ‘女 지우기’ 급급”\n",
      "29: 내년 추석 연휴는 1주일…개천절부터 한글날까지 쉰다\n",
      "30: '채 해병 사건 회수' 시작점에 윤석열... 새 통화 기록 나왔다\n",
      "31: 끝모를 쌀값 하락…“재고 15만t 신속 격리를”\n",
      "32: 영국 명소 스톤헨지에 환경단체 주황 물감 스프레이 분사\n",
      "33: 푸틴, 또 김정은에게 ‘러시아판 롤스로이스’ 아우루스 선물\n",
      "34: 2025년 직장인 쉬는 날 119일…3일 이상 연휴 6번\n",
      "35: 실질 지원 기대감 “해봐야”…익명 출산 딜레마 “해봤자”\n",
      "36: \"음주운전하면 무조건 튀어라\"…'음주 혐의' 빠진 김호중에 뿔난 여론\n",
      "37: “시청률 0%, 터질게 터졌다” 넷플릭스발 초유의 사태 ‘발칵’\n",
      "38: \"자식 돈은 자식 돈, 어디 숟가락을 얹나\"…박세리 논란에 손흥민 父 손웅정 발언 재조명\n",
      "39: 어제 ‘인구국가비상사태’ 보셨나요…‘진짜 비상사태’ 3가지 빠졌던데\n",
      "40: 납품 전선 이상 無… 韓방산, 2분기 호실적 기대\n",
      "41: \"TV수신료 고지서 7월10일 도착한다\"\n",
      "42: 제로라니까 제로인 줄 알았어? '제로슈거'의 거짓말 [추적+]\n",
      "43: \"자식 돈에 어디 숟가락 얹나\"…박세리 논란에 손흥민父 재조명\n",
      "44: \"20년 넘게 알고 지낸 기자 질문에…\" 박세리 심경 고백\n",
      "45: “한달에 3천만원 저축, 연봉 5~6억”…악착같이 모은다는 무명개그맨의 정체\n",
      "46: 이재명·한동훈 ‘단두대 매치’ 성사되나\n",
      "47: [인사이드 스토리]반전 거듭하는 애플…아이폰 슈퍼사이클 맞을까\n",
      "48: AI가 광고를 만든다? \"중요한 건 인간의 판단력\"\n",
      "49: [단독] 영화숙·재생원 악몽, 국제사회에 첫 증언\n",
      "50: 尹 대통령 \"인구 국가비상사태\"…저출생 대책 드라이브 시동\n",
      "51: \"이게 무슨 추태냐\"...'대구 공무원 치킨집 갑질' 탄식에 홍준표 한마디\n",
      "52: Summit of two loners: Kim breaks seclusion with Putin by his side\n",
      "53: 푸틴, 21시간 방북 종료…김정은, 비행기 뜰 때까지 손 흔들어\n",
      "54: \"李 민주당의 아버지\" 찬사에…진중권 \"아바이 수령, 이재명 주석 만세!\"\n",
      "55: “목에 여자 문신”…아동성범죄 저지른 한국 남성 공개한 나라\n",
      "56: 푸틴, 24년만의 방북…21시간 머물고 김정은 배웅 속 평양 떠나\n",
      "57: 하늘에서 내려오는 ‘공짜’ 다이어트 보조제… 지금 실컷 누리자\n",
      "58: 종로 포차거리에서 흉기난동, 휴무 경찰이 제압\n",
      "59: 정신질환으로 우발적 살인? '심신미약'이면 여성 살해해도 되나\n",
      "60: 한국인이 가장 좋아하는 유튜버 1위는?\n",
      "61: BBQ, '4000원 할인 쿠폰' 프로모션...민심 잡기 나선다\n",
      "62: 올해 장마 시작...제주 밤새 장맛비 내려\n",
      "63: 尹, '채상병 기록 회수 당일' 개인폰으로 전방위 전화…이시원도 집중 연락\n",
      "64: 방문 요양보호사들 ‘임금 올려라’ 국가에 소송 제기\n",
      "65: '김건희 논문 검증' 학생들 몰표‥'숙대'의 선택은\n",
      "66: 서울 35도 ‘찜통더위’…제주 거센 장맛비\n",
      "67: 징역 9년 6개월 이화영 판결문 속 이재명\n",
      "68: 카카오, '개인정보위 대상' 행정소송 준비…주요 로펌서 제안서 받아\n",
      "69: 내년 추석은 7일 쉰다…주5일 직장인 휴일 '119일'\n",
      "70: “비둘기, 멧돼지, 다람쥐 여러분…피임하세요” 과학자들 피임약 뿌려 개체수 조절 시험중\n",
      "71: 바지 벗고 길에 쪼그려 앉은 아이…제주 발칵 뒤집은 영상 [잇슈 키워드]\n",
      "72: 프랑스 13세 소년들, 12세 유대인 소녀 집단 성폭행 파문\n",
      "73: [단독]‘몰카 안경’ 쓰고 유치장-판사 몰래 찍은 30대 여성 구속기소\n",
      "74: 에어컨 전기료 줄이는 방법은?\n",
      "75: 정용진 신세계 '신상필벌' 인사에 직원들 ‘긴장’\n",
      "76: 푸틴의 '탈(脫)달러'…\"베트남과 자국통화 무역 60%로 증가\"\n",
      "77: 프랑스서 12세 유대인 소녀 집단 성폭행 발생…대중 '분노'\n",
      "78: 제주 길거리서 당당하게 대변보는 외국인 아이… 서경덕 \"반드시 처벌해 본보기 보여야\"\n",
      "79: Putin, Kim sign strategic partnership as North backs Russia's war in Ukraine\n",
      "80: 길거리서 용변 본 아이, 엄마는 나 몰라라.. \"몰상식 행위  처벌해야\"\n",
      "81: \"역대 가장 더운 6월\"..정읍 37.5도까지 치솟아\n",
      "82: 내년 '빨간 날'은 언제?…\"추석 대박\" 2025년 월력요항 발표\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = 'https://news.naver.com'\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "# headlines = soup.find_all(class_='cjs_t')\n",
    "# i=1\n",
    "# for headline in headlines:\n",
    "#     print(f\"{i}: {headline.text.strip()}\")\n",
    "#     i+=1\n",
    "headlines = soup.select('.cjs_t')\n",
    "for idx,headline in enumerate(headlines):\n",
    "    print(f\"{idx+1}: {headline.get_text().strip()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
