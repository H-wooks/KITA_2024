#####################################################################################################
#############################################   OverView  ###########################################
##################################################################################################### 

[분류 모델과 회귀모델 차이]
분류 모델 (Classification Model)
목적: 분류 모델은 데이터 포인트를 서로 다른 클래스 또는 범주로 분류하는 것이 목적. 이메일이 스팸인지 아닌지, 이미지가 고양이인지 개인지 구분하는 작업 등
출력: 분류 모델의 출력은 이산적인 값. 특정 클래스 또는 레이블을 예측. 예를 들어, 이메일을 '스팸' 또는 '정상'으로 분류

<알고리즘 예시>
로지스틱 회귀 (Logistic Regression)
결정 트리 (Decision Tree)
랜덤 포레스트 (Random Forest)
서포트 벡터 머신 (Support Vector Machine)
나이브 베이즈 (Naive Bayes)
인공 신경망 (Artificial Neural Networks)
평가 지표: 정확도 (Accuracy), 정밀도 (Precision), 재현율 (Recall), F1 점수 (F1 Score), ROC-AUC 등.

회귀 모델 (Regression Model)
목적: 회귀 모델은 연속적인 숫자 값을 예측하는 것이 목적. 예를 들어, 주택 가격 예측, 주식 가격 예측, 온도 예측 등
출력: 회귀 모델의 출력은 연속적인 값. 특정 범위 내의 숫자를 예측. 예를 들어, 주택의 가격을 달러 단위로 예측

<알고리즘 예시>
선형 회귀 (Linear Regression)
릿지 회귀 (Ridge Regression)
라쏘 회귀 (Lasso Regression)
결정 트리 회귀 (Decision Tree Regression)
랜덤 포레스트 회귀 (Random Forest Regression)
서포트 벡터 회귀 (Support Vector Regression)
평가 지표: 평균 제곱 오차 (Mean Squared Error), 평균 절대 오차 (Mean Absolute Error), R² 점수 (R² Score) 등.

#####################################################################################################
#############################################  Data Load  ###########################################
#####################################################################################################

####################################################### 와인 DataSet
from sklearn.datasets import load_wine
wineDB = load_wine()
X, y=wineDB.data, wineDB.target

####################################################### 당뇨병 DataSet
from sklearn.datasets import load_diabetes
diabetes = load_diabetes()
X, y = diabetes.data, diabetes.target


####################################################### 타이타닉 DataSet
url='https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv'
data_org=pd.read_csv(url)
data = data_org.copy()
# 필요한 컬럼 선택 및 결측치 처리
data = data[['Survived', 'Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare']]
data = data.dropna()

# 범주형 변수 인코딩
data['Sex'] = data['Sex'].map({'male': 0, 'female': 1})

# 특성과 레이블 분리
X = data.drop('Survived', axis=1)
y = data['Survived']



#####################################################################################################
##############################################  검증방법  ###########################################
#####################################################################################################

########################################################### accuracy_score
from sklearn.metrics import accuracy_score
accuracy = accuracy_score(y_test, y_pred)

########################################################### Mean Squared Error
from sklearn.metrics import accuracy_score, mean_squared_error
mse = mean_squared_error(y_test, y_pred)

########################################################### ConfusionMatrix, ClassificationReport
from sklearn.metrics import confusion_matrix, classification_report
conf_matrix = confusion_matrix(y_test, y_pred)
class_report = classification_report(y_test, y_pred)

#####################################################################################################
########################################## 분류: DecisionTree #######################################
##################################################################################################### 
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=40)

# 표준화 적용
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# 모델 학습 예측
from sklearn.tree import DecisionTreeClassifier
dt = DecisionTreeClassifier()
dt.fit(X_train_scaled, y_train)
y_pred = dt.predict(X_test_scaled)

from sklearn.metrics import accuracy_score
accuracy = accuracy_score(y_test, y_pred)





#####################################################################################################
########################################## 분류: 로지스틱 회귀 ######################################
##################################################################################################### 








#####################################################################################################
######################################## 분류: 다양한 algorithms ####################################
##################################################################################################### 
from sklearn.datasets import load_wine
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.naive_bayes import GaussianNB
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.svm import SVC
from sklearn.neural_network import MLPClassifier
from sklearn.metrics import accuracy_score, mean_squared_error

# 데이터 로드
wineDB = load_wine()
X, y = wineDB.data, wineDB.target

# 데이터 분할
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=40)

# 모델 리스트 생성
models = {
    "Decision Tree": DecisionTreeClassifier(random_state=40),
    "Logistic Regression": LogisticRegression(max_iter=10000,random_state=40),
    "Naive Bayes": GaussianNB(),
    "Random Forest": RandomForestClassifier(random_state=40),
    "SVM": SVC(random_state=40),
    "Neural Network": MLPClassifier(max_iter=10000,random_state=40),
    "Gradient Boosting": GradientBoostingClassifier(random_state=40)
}

for model_name, model in models.items():
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)
    accuracy = accuracy_score(y_test, y_pred)
    print(f"{model_name} Accuracy: {accuracy:.2f}")
    mse = mean_squared_error(y_test, y_pred)
    print(f"{model_name} Mean Squared Error: {mse:.2f}")



#####################################################################################################
########################################## 하이퍼 파라미터 튜닝 #####################################
##################################################################################################### 
from sklearn.datasets import load_diabetes

# 데이터 로드
diabetes = load_diabetes()
X, y = diabetes.data, diabetes.target

# 학습 데이터와 테스트 데이터로 분리
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# 표준화 적용
from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# 모델 리스트 생성
from sklearn.linear_model import LinearRegression
from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor

models = {
    "Linear Regression": LinearRegression(),
    "Decision Tree": DecisionTreeRegressor(),
    "Random Forest": RandomForestRegressor(),
    "Gradient Boosting": GradientBoostingRegressor()
}

# 하이퍼파라미터 튜닝을 위한 그리드 설정
from sklearn.model_selection import GridSearchCV

param_grids = {
    "Decision Tree": {
        'max_depth': [None, 10, 20, 30],
        'min_samples_split': [2, 10, 20]
    },
    "Random Forest": {
        'n_estimators': [50, 100, 200],
        'max_depth': [None, 10, 20, 30],
        'min_samples_split': [2, 10, 20]
    },
    "Gradient Boosting": {
        'n_estimators': [50, 100, 200],
        'learning_rate': [0.01, 0.1, 0.2],
        'max_depth': [3, 5, 7]
    }
}

# 각 모델에 대해 학습 및 평가
from sklearn.metrics import mean_squared_error

results = []
for model_name, model in models.items():
    if model_name in param_grids:
        grid_search = GridSearchCV(model, param_grids[model_name], cv=5, scoring='neg_mean_squared_error')
        grid_search.fit(X_train_scaled, y_train)
        best_model = grid_search.best_estimator_
        y_pred = best_model.predict(X_test_scaled)
        mse = mean_squared_error(y_test, y_pred)
        print(f"{model_name} (Tuned) Mean Squared Error: {mse:.2f}")
        results.append({"Model": model_name + " (Tuned)", "Mean Squared Error": mse})
    else:
        model.fit(X_train_scaled, y_train)
        y_pred = model.predict(X_test_scaled)
        mse = mean_squared_error(y_test, y_pred)
        print(f"{model_name} Mean Squared Error: {mse:.2f}")
        results.append({"Model": model_name, "Mean Squared Error": mse})

# 결과 데이터프레임 생성
results_df = pd.DataFrame(results)
print(results_df)







##################################################################### XXXX

####################################### XXX
#####################################################################################################
############################################### Encoding ############################################
##################################################################################################### 




#####################################################################################################
################################################# EXAMPLES ##########################################
##################################################################################################### 

######################################################## Q. 

######################################################## Q. 

######################################################## Q. 

######################################################## Q. 

######################################################## Q. 

######################################################## Q. 

######################################################## Q. 

######################################################## Q. 

######################################################## Q. 

######################################################## Q. 

######################################################## Q. 

######################################################## Q. 

######################################################## Q. 

######################################################## Q. 



